{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de52ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68433459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar la estrucutra para las ids, tengo que usar las url para las series y con eso sacar los map id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e76780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_k(valor):\n",
    "    \"remove k in money columns and change the format to int\"\n",
    "    if 'k' in valor:\n",
    "        return int(float(valor.replace('k', '')) * 1000)\n",
    "\n",
    "def find_files_by_prefix(root_folder, prefix):\n",
    "    matched_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for file in filenames:\n",
    "            if file.startswith(prefix):\n",
    "                full_path = os.path.join(dirpath, file)\n",
    "                matched_files.append(full_path)\n",
    "    return matched_files\n",
    "\n",
    "def concat_from_list(file_list,encoding='iso-8859-1'):\n",
    "    dataframes = []\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            df = pd.read_csv(file,encoding=encoding)\n",
    "            if not df.empty:\n",
    "                dataframes.append(df)\n",
    "            else:\n",
    "                print(f\"empty file: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    if dataframes:\n",
    "        return pd.concat(dataframes, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Load file fail\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def concat_csv_from_different_folders(folder=\"csv\",prefix=None):\n",
    "    if prefix is None:\n",
    "        print(\"Add a prefix\")\n",
    "\n",
    "    file_list = find_files_by_prefix(root_folder=folder,prefix=prefix)\n",
    "    df_concat = concat_from_list(file_list)\n",
    "    return df_concat\n",
    "\n",
    "def get_game_instance(value):\n",
    "    last_char = value.split(\"-\")[-1]\n",
    "    return last_char\n",
    "\n",
    "def text_to_index(df,name,number=0,extra_id=\"\"):\n",
    "    name_id = name+'_id'\n",
    "    df[name_id] = df.index + number\n",
    "    df[name_id] = name + \"_\" + df[name_id].astype(str) + extra_id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1316b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_names(folder='csv'):\n",
    "    tournament_list = []\n",
    "    for name in os.listdir(folder):\n",
    "        path = os.path.join(folder, name)\n",
    "        if os.path.isdir(path):\n",
    "            tournament_list.append(name)\n",
    "    return tournament_list\n",
    "\n",
    "def region_by_id(touranment_name, region):\n",
    "    for _, row in region.iterrows():\n",
    "        if row['region'].lower() in touranment_name.lower():\n",
    "            return row['reg_id']\n",
    "    return \"reg_4\"\n",
    "\n",
    "def create_draft_table(df):\n",
    "    filas_transformadas = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        picks = [\n",
    "            row['team_1_select_1'], row['team_2_select_1'],\n",
    "            row['team_1_select_2'], row['team_2_select_2'],\n",
    "            row['team_1_select_3'], row['team_2_select_3'],\n",
    "            row['decider']\n",
    "        ]\n",
    "\n",
    "        for pick_num, map_name in enumerate(picks, start=1):\n",
    "            filas_transformadas.append({\n",
    "                'team': row['team'],\n",
    "                'series_id': row['series_id'],\n",
    "                \n",
    "                'order': row['order'],\n",
    "                'bo': row['bo'],\n",
    "                'pick': pick_num,\n",
    "                'map_name': map_name,\n",
    "                \"match_instance\" : row[\"match_instance\"],\n",
    "                \"vlr_id\":row[\"vlr_id\"],\n",
    "                'series_id':row['series_id'],\n",
    "                'reg_id':row['reg_id'],\n",
    "                'tour_id':row['tour_id']\n",
    "            })\n",
    "\n",
    "    new_df = pd.DataFrame(filas_transformadas)\n",
    "    return new_df\n",
    "\n",
    "def first_ban(row):\n",
    "    if (row['match_instance'] != \"gf\"):\n",
    "        if (row['pick'] == 1):        \n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif (row['match_instance'] == \"gf\"):\n",
    "        if (row['pick'] == 1 or row['pick'] == 2):        \n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    else:\n",
    "         return 0\n",
    "\n",
    "def second_ban(row):\n",
    "    \n",
    "        if row['pick'] == 5 and row['bo'] == 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "def first_pick(row):\n",
    "\n",
    "        if row['pick'] == 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "   \n",
    "def second_pick(row):\n",
    "        if row['pick'] == 5 and row['bo'] == 5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def decider_pick(row):\n",
    "    if row['pick'] == 7:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a3d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should round only once.\n",
    "#This should be create in another way, probably from a json \n",
    "region_name = [\"americas\",\"emea\",\"china\",\"pacific\",\"global\"]\n",
    "\n",
    "df_region = pd.DataFrame(data=region_name, columns=[\"region\"])\n",
    "text_to_index(df_region,\"reg\",number=0,extra_id=\"\")\n",
    "\n",
    "#This should run each time a new tournament is add\n",
    "\n",
    "tournaments = tournament_names('csv')\n",
    "df_tournaments = pd.DataFrame(data=tournaments,columns=[\"tournament_name\"])\n",
    "tournament_name_list = ['Valorant Masters Toronto 2025', 'VCT 2025: Americas Stage 1',\n",
    "       'VCT 2025: China Stage 1', 'VCT 2025: EMEA Stage 1',\n",
    "       'VCT 2025: Pacific Stage 1']\n",
    "df_tournaments[\"event\"] = pd.Series(tournament_name_list)\n",
    "\n",
    "df_tournaments['reg_id'] = df_tournaments['event'].apply(lambda x: region_by_id(x, df_region))\n",
    "\n",
    "text_to_index(df_tournaments,\"tour\")\n",
    "\n",
    "df_region.to_csv(path_or_buf='tables/table_region.csv',index=False,encoding='iso-8859-1')\n",
    "df_tournaments.to_csv(path_or_buf='tables/table_tournament.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "589a88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_draft_concat = concat_csv_from_different_folders(folder=\"csv\", prefix=\"draft_\")\n",
    "df_team = pd.DataFrame(df_draft_concat[\"team\"].unique(), columns=[\"team\"])\n",
    "\n",
    "text_to_index(df_team,\"team\")\n",
    "\n",
    "df_team.to_csv(path_or_buf='tables/table_teams.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CREO QUE NO LO VOY A USAR \n",
    "\n",
    "# #teams by region:\n",
    "# df_teams_china = pd.read_csv(\"csv/vct_2025_china_stage_1/draft_vct_2025_china_stage_1.csv\",encoding='iso-8859-1')\n",
    "# df_teams_americas = pd.read_csv(\"csv/vct_2025_americas_stage_1/draft_vct_2025_americas_stage_1.csv\",encoding='iso-8859-1')\n",
    "# df_teams_emea = pd.read_csv(\"csv/vct_2025_emea_stage_1/draft_vct_2025_emea_stage_1.csv\",encoding='iso-8859-1')\n",
    "# df_teams_pacific = pd.read_csv(\"csv/vct_2025_pacific_stage_1/draft_vct_2025_pacific_stage_1.csv\",encoding='iso-8859-1')\n",
    "\n",
    "# #this should run one by year\n",
    "# df_teams_amer_for_merge = pd.DataFrame(df_teams_americas[\"team\"].unique(),columns=[\"team\"])\n",
    "# df_teams_amer_for_merge[\"team_reg\"] = \"reg_0\"\n",
    "\n",
    "# df_teams_emea_for_merge = pd.DataFrame(df_teams_emea[\"team\"].unique(),columns=[\"team\"])\n",
    "# df_teams_emea_for_merge[\"team_reg\"] = \"reg_1\"\n",
    "\n",
    "# df_teams_china_for_merge = pd.DataFrame(df_teams_china[\"team\"].unique(),columns=[\"team\"])\n",
    "# df_teams_china_for_merge[\"team_reg\"] = \"reg_2\"\n",
    "\n",
    "# df_teams_apac_for_merge = pd.DataFrame(df_teams_pacific[\"team\"].unique(),columns=[\"team\"])\n",
    "# df_teams_apac_for_merge[\"team_reg\"] = \"reg_3\"\n",
    "\n",
    "# df_teams_concat = pd.concat(\n",
    "#     [\n",
    "#         df_teams_amer_for_merge,\n",
    "#         df_teams_emea_for_merge,\n",
    "#         df_teams_china_for_merge,\n",
    "#         df_teams_apac_for_merge,\n",
    "#     ],\n",
    "#     ignore_index=True,\n",
    "# )\n",
    "\n",
    "# text_to_index(df_teams_concat,\"team\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c09e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update when a new player is add\n",
    "df_players_stats = concat_csv_from_different_folders(folder=\"csv\", prefix=\"player_stats\")\n",
    "df_players = df_players_stats[['player','team']].drop_duplicates(subset=['player'],ignore_index=True)\n",
    "text_to_index(df_players,\"player\")\n",
    "\n",
    "df_players_id = pd.merge(df_players, df_team[[\"team\",\"team_id\"]],how=\"left\", left_on=\"team\", right_on=\"team\")\n",
    "\n",
    "#Le saco las regiones a los players ? \n",
    "#df_players_id = pd.merge(df_players_id, df_teams_concat[[\"team_id\",\"region\"]],how=\"left\", left_on=\"team_id\", right_on=\"team_id\")\n",
    "\n",
    "df_players_id.to_csv(path_or_buf='tables/table_players.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_id_vlr(url):\n",
    "    match = re.search(r\"vlr\\.gg/(\\d+)\", url)\n",
    "    if match:\n",
    "        vlr_id = match.group(1)\n",
    "        return vlr_id\n",
    "\n",
    "\n",
    "df_round_detail = concat_csv_from_different_folders(folder=\"csv\", prefix=\"round_detail\")\n",
    "\n",
    "df_filter_map = df_round_detail[\"map\"] != \"all\"\n",
    "df_round_detail_filter = df_round_detail[df_filter_map]\n",
    "df_round_detail_filter[\"vlr_id\"] = df_round_detail_filter[\"source_url\"].apply(\n",
    "    match_id_vlr\n",
    ")\n",
    "df_round_detail_filter[\"vlr_id-map\"] = (\n",
    "    df_round_detail_filter[\"vlr_id\"] + \"-\" + df_round_detail_filter[\"map\"]\n",
    ")\n",
    "\n",
    "df_maps_id = pd.DataFrame(\n",
    "    df_round_detail_filter[\"vlr_id-map\"].unique(), columns=[\"vlr_id-map\"]\n",
    ")\n",
    "text_to_index(df_maps_id, \"map\")\n",
    "\n",
    "df_maps_id[[\"vlr_id\", \"map\"]] = df_maps_id[\"vlr_id-map\"].str.rsplit(\n",
    "    \"-\", n=1, expand=True\n",
    ")\n",
    "\n",
    "df_match_id = pd.DataFrame(data=df_maps_id[\"vlr_id\"].unique(), columns=[\"vlr_id\"])\n",
    "text_to_index(df_match_id, \"series\")\n",
    "\n",
    "df_round_detail_filter = pd.merge(\n",
    "    df_round_detail_filter,\n",
    "    df_tournaments[[\"event\", \"reg_id\", \"tour_id\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"event\",\n",
    "    right_on=\"event\",\n",
    ")\n",
    "\n",
    "df_match_id = pd.merge(\n",
    "    df_match_id,\n",
    "    df_round_detail_filter[[\"vlr_id\", \"reg_id\", \"tour_id\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"vlr_id\",\n",
    "    right_on=\"vlr_id\",\n",
    ")\n",
    "\n",
    "df_match_id.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df_maps_id = pd.merge(\n",
    "    df_maps_id,\n",
    "    df_match_id,\n",
    "    how=\"left\",\n",
    "    left_on=\"vlr_id\",\n",
    "    right_on=\"vlr_id\",\n",
    ")\n",
    "\n",
    "df_tournament_played = df_round_detail_filter[[\"teamA\",\"event\",\"reg_id\",\"tour_id\"]].copy()\n",
    "df_tournament_played.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df_maps_id.to_csv(path_or_buf='tables/table_maps_id.csv',index=False,encoding='iso-8859-1')\n",
    "\n",
    "df_match_id.to_csv(path_or_buf='tables/table_match_id.csv',index=False,encoding='iso-8859-1')\n",
    "\n",
    "#df_round_detail_filter.to_csv(path_or_buf='tables/table_round_detail.csv',index=False,encoding='iso-8859-1') Esto hay que limpiar\n",
    "\n",
    "df_tournament_played.to_csv(path_or_buf='tables/table_tournament_played.csv',index=False,encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bab24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Player performance\n",
    "df_player_performance = concat_csv_from_different_folders(folder=\"csv\",prefix=\"player_performance\")\n",
    "\n",
    "df_filter_map = df_player_performance[\"map\"] != \"all\"\n",
    "df_player_performance = df_player_performance[df_filter_map]\n",
    "df_player_performance[\"vlr_id\"] = df_player_performance[\"source_url\"].apply(\n",
    "    match_id_vlr\n",
    ")\n",
    "df_player_performance[\"vlr_id-map\"] = (\n",
    "    df_player_performance[\"vlr_id\"] + \"-\" + df_player_performance[\"map\"]\n",
    ")\n",
    "\n",
    "df_player_performance = pd.merge(df_player_performance, df_maps_id[[\"vlr_id-map\",\"map_id\",\"series_id\",\"reg_id\",\"tour_id\"]],how=\"left\", left_on=\"vlr_id-map\", right_on=\"vlr_id-map\")\n",
    "\n",
    "df_player_performance.to_csv(path_or_buf='tables/table_player_performance.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Team economy stats \n",
    "\n",
    "df_team_economy = concat_csv_from_different_folders(folder=\"csv\", prefix=\"team_economy\")\n",
    "\n",
    "columns_update = [\"team_a_economy\",\"team_b_economy\",\"team_a_bank\",\"team_b_bank\"]\n",
    "\n",
    "for column_name in columns_update:\n",
    "    df_team_economy[column_name] = df_team_economy[column_name].apply(convert_k)\n",
    "\n",
    "df_team_economy[\"vlr_id\"] = df_team_economy[\"source_url\"].apply(\n",
    "    match_id_vlr\n",
    ")\n",
    "df_team_economy[\"vlr_id-map\"] = (\n",
    "    df_team_economy[\"vlr_id\"] + \"-\" + df_team_economy[\"map\"]\n",
    ")\n",
    "\n",
    "df_team_economy = pd.merge(df_team_economy, df_maps_id[[\"vlr_id-map\",\"map_id\",\"series_id\",\"reg_id\",\"tour_id\"]],how=\"left\", left_on=\"vlr_id-map\", right_on=\"vlr_id-map\")\n",
    "\n",
    "df_team_economy.to_csv(path_or_buf='tables/table_team_economy.csv',index=False,encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e46ac175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#player stats\n",
    "\n",
    "df_player_stats = concat_csv_from_different_folders(folder=\"csv\", prefix=\"player_stats\")\n",
    "\n",
    "df_filter_map = df_player_stats[\"map\"] != \"all\"\n",
    "df_player_stats = df_player_stats[df_filter_map]\n",
    "df_player_stats[\"vlr_id\"] = df_player_stats[\"source_url\"].apply(\n",
    "    match_id_vlr\n",
    ")\n",
    "df_player_stats[\"vlr_id-map\"] = (\n",
    "    df_player_stats[\"vlr_id\"] + \"-\" + df_player_stats[\"map\"]\n",
    ")\n",
    "\n",
    "df_player_stats = pd.merge(df_player_stats, df_maps_id[[\"vlr_id-map\",\"map_id\",\"series_id\",\"reg_id\",\"tour_id\"]],how=\"left\", left_on=\"vlr_id-map\", right_on=\"vlr_id-map\")\n",
    "\n",
    "df_player_stats.to_csv(path_or_buf='tables/table_player_stats.csv',index=False,encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draft (raro hay que revisar)\n",
    "df_draft_concat = concat_csv_from_different_folders(folder=\"csv\", prefix=\"draft_\")\n",
    "df_draft_concat[\"match_instance\"] = df_draft_concat[\"source_url\"].apply(\n",
    "    get_game_instance\n",
    ")\n",
    "df_draft_concat[\"vlr_id\"] = df_draft_concat[\"source_url\"].apply(match_id_vlr)\n",
    "\n",
    "df_draft_concat = pd.merge(\n",
    "    df_draft_concat,\n",
    "    df_maps_id[[\"vlr_id\", \"series_id\", \"reg_id\", \"tour_id\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"vlr_id\",\n",
    "    right_on=\"vlr_id\",\n",
    ")\n",
    "df_draft_concat.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df_draft_concat_fix = create_draft_table(df_draft_concat)\n",
    "\n",
    "df_draft_concat_fix['1st_ban'] = df_draft_concat_fix.apply(first_ban,axis=1)\n",
    "\n",
    "df_draft_concat_fix['2nd_ban'] = df_draft_concat_fix.apply(second_ban,axis=1)\n",
    "\n",
    "df_draft_concat_fix['1st_pick'] = df_draft_concat_fix.apply(first_pick, axis=1)\n",
    "\n",
    "df_draft_concat_fix['2nd_pick'] = df_draft_concat_fix.apply(second_pick,axis=1)\n",
    "\n",
    "df_draft_concat_fix['decider'] = df_draft_concat_fix.apply(decider_pick,axis=1)\n",
    "\n",
    "df_draft_concat_fix.to_csv(path_or_buf='tables/table_draft.csv',index=False,encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c3e2adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round stats\n",
    "\n",
    "df_round_concat = concat_csv_from_different_folders(folder=\"csv\", prefix=\"round_detail\")\n",
    "\n",
    "#table with the maps\n",
    "df_maps_name_id = pd.DataFrame(df_round_concat[\"map\"].unique(), columns=[\"map\"])\n",
    "text_to_index(df_maps_name_id,\"map\")\n",
    "\n",
    "df_maps_name_id.to_csv(path_or_buf='tables/table_maps_name_id.csv',index=False,encoding='iso-8859-1')\n",
    "\n",
    "df_round_concat[\"vlr_id\"] = df_round_concat[\"source_url\"].apply(\n",
    "    match_id_vlr\n",
    ")\n",
    "df_round_concat[\"vlr_id-map\"] = (\n",
    "    df_round_concat[\"vlr_id\"] + \"-\" + df_round_concat[\"map\"]\n",
    ")\n",
    "\n",
    "df_round_concat = pd.merge(df_round_concat, df_maps_id[[\"vlr_id-map\",\"map_id\",\"series_id\",\"reg_id\",\"tour_id\"]],how=\"left\", left_on=\"vlr_id-map\", right_on=\"vlr_id-map\")\n",
    "\n",
    "df_round_concat.to_csv(path_or_buf='tables/table_round_info.csv',index=False,encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9035b2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vlr_id-map</th>\n",
       "      <th>map_id</th>\n",
       "      <th>vlr_id</th>\n",
       "      <th>map</th>\n",
       "      <th>series_id</th>\n",
       "      <th>reg_id</th>\n",
       "      <th>tour_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>450076-Split</td>\n",
       "      <td>map_236</td>\n",
       "      <td>450076</td>\n",
       "      <td>Split</td>\n",
       "      <td>series_95</td>\n",
       "      <td>reg_2</td>\n",
       "      <td>tour_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>450076-Fracture</td>\n",
       "      <td>map_237</td>\n",
       "      <td>450076</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>series_95</td>\n",
       "      <td>reg_2</td>\n",
       "      <td>tour_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vlr_id-map   map_id  vlr_id       map  series_id reg_id tour_id\n",
       "236     450076-Split  map_236  450076     Split  series_95  reg_2  tour_2\n",
       "237  450076-Fracture  map_237  450076  Fracture  series_95  reg_2  tour_2"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_maps_id[df_maps_id[\"series_id\"] == \"series_95\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e4b37fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2K</th>\n",
       "      <th>3K</th>\n",
       "      <th>4K</th>\n",
       "      <th>5K</th>\n",
       "      <th>1v1</th>\n",
       "      <th>1v2</th>\n",
       "      <th>1v3</th>\n",
       "      <th>1v4</th>\n",
       "      <th>1v5</th>\n",
       "      <th>ECON</th>\n",
       "      <th>PL</th>\n",
       "      <th>DE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "      <td>3680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.623641</td>\n",
       "      <td>0.788859</td>\n",
       "      <td>0.166033</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>0.111141</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>51.713587</td>\n",
       "      <td>1.470652</td>\n",
       "      <td>0.437772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.645188</td>\n",
       "      <td>0.921924</td>\n",
       "      <td>0.415634</td>\n",
       "      <td>0.136620</td>\n",
       "      <td>0.457587</td>\n",
       "      <td>0.330370</td>\n",
       "      <td>0.165921</td>\n",
       "      <td>0.061570</td>\n",
       "      <td>0.016485</td>\n",
       "      <td>16.289112</td>\n",
       "      <td>1.845694</td>\n",
       "      <td>0.690822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2K           3K           4K           5K          1v1  \\\n",
       "count  3680.000000  3680.000000  3680.000000  3680.000000  3680.000000   \n",
       "mean      2.623641     0.788859     0.166033     0.019022     0.204348   \n",
       "std       1.645188     0.921924     0.415634     0.136620     0.457587   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       2.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       4.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max      11.000000     5.000000     3.000000     1.000000     3.000000   \n",
       "\n",
       "               1v2          1v3          1v4          1v5         ECON  \\\n",
       "count  3680.000000  3680.000000  3680.000000  3680.000000  3680.000000   \n",
       "mean      0.111141     0.027174     0.003804     0.000272    51.713587   \n",
       "std       0.330370     0.165921     0.061570     0.016485    16.289112   \n",
       "min       0.000000     0.000000     0.000000     0.000000     8.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000    41.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000    50.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000    61.000000   \n",
       "max       3.000000     2.000000     1.000000     1.000000   180.000000   \n",
       "\n",
       "                PL           DE  \n",
       "count  3680.000000  3680.000000  \n",
       "mean      1.470652     0.437772  \n",
       "std       1.845694     0.690822  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       1.000000     0.000000  \n",
       "75%       2.000000     1.000000  \n",
       "max      11.000000     5.000000  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_player_performance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6704e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>player</th>\n",
       "      <th>agent</th>\n",
       "      <th>ratingBoth</th>\n",
       "      <th>ratingT</th>\n",
       "      <th>rating-ct</th>\n",
       "      <th>acsBoth</th>\n",
       "      <th>acsT</th>\n",
       "      <th>acsCT</th>\n",
       "      <th>killsBoth</th>\n",
       "      <th>...</th>\n",
       "      <th>fdCT</th>\n",
       "      <th>fk-fdBoth</th>\n",
       "      <th>fk-fdT</th>\n",
       "      <th>fk-fdCT</th>\n",
       "      <th>map</th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>date-map</th>\n",
       "      <th>map_id</th>\n",
       "      <th>series_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>NAVI</td>\n",
       "      <td>koalanoob</td>\n",
       "      <td>Raze</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.56</td>\n",
       "      <td>359.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Split</td>\n",
       "      <td>2025-04-09 13:15:00</td>\n",
       "      <td>VCT 2025: EMEA Stage 1</td>\n",
       "      <td>2025-04-09 13:15:00-Split</td>\n",
       "      <td>map_304</td>\n",
       "      <td>series_121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team     player agent  ratingBoth  ratingT  rating-ct  acsBoth   acsT  \\\n",
       "1991  NAVI  koalanoob  Raze        1.75     4.07       1.56    359.0  683.0   \n",
       "\n",
       "      acsCT  killsBoth  ...  fdCT  fk-fdBoth  fk-fdT  fk-fdCT    map  \\\n",
       "1991  333.0       16.0  ...   0.0        5.0     1.0      1.0  Split   \n",
       "\n",
       "                     date                   event                   date-map  \\\n",
       "1991  2025-04-09 13:15:00  VCT 2025: EMEA Stage 1  2025-04-09 13:15:00-Split   \n",
       "\n",
       "       map_id   series_id  \n",
       "1991  map_304  series_121  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_player_stats[df_player_stats[\"ratingT\"] > 4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
