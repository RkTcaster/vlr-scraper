{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de52ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e76780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_k(valor):\n",
    "    \"remove k in money columns and change the format to int\"\n",
    "    if 'k' in valor:\n",
    "        return int(float(valor.replace('k', '')) * 1000)\n",
    "\n",
    "def find_files_by_prefix(root_folder, prefix):\n",
    "    matched_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for file in filenames:\n",
    "            if file.startswith(prefix):\n",
    "                full_path = os.path.join(dirpath, file)\n",
    "                matched_files.append(full_path)\n",
    "    return matched_files\n",
    "\n",
    "def concat_from_list(file_list,encoding='iso-8859-1'):\n",
    "    dataframes = []\n",
    "    for file in file_list:\n",
    "        try:\n",
    "            df = pd.read_csv(file,encoding=encoding)\n",
    "            if not df.empty:\n",
    "                dataframes.append(df)\n",
    "            else:\n",
    "                print(f\"empty file: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    if dataframes:\n",
    "        return pd.concat(dataframes, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Load file fail\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def concat_csv_from_different_folders(folder=\"csv\",prefix=None):\n",
    "    if prefix is None:\n",
    "        print(\"Add a prefix\")\n",
    "\n",
    "    file_list = find_files_by_prefix(root_folder=folder,prefix=prefix)\n",
    "    df_concat = concat_from_list(file_list)\n",
    "    return df_concat\n",
    "\n",
    "def get_game_instance(value):\n",
    "    last_char = value.split(\"-\")[-1]\n",
    "    return last_char\n",
    "\n",
    "def text_to_index(df,name,number=0,extra_id=\"\"):\n",
    "    \n",
    "    name_id = name+'_id'\n",
    "    df[name_id] = df.index + number\n",
    "    df[name_id] = name + \"_\" + df[name_id].astype(str) + extra_id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1316b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_names(folder='csv'):\n",
    "    tournament_list = []\n",
    "    for name in os.listdir(folder):\n",
    "        path = os.path.join(folder, name)\n",
    "        if os.path.isdir(path):\n",
    "            tournament_list.append(name)\n",
    "    return tournament_list\n",
    "\n",
    "def region_by_id(touranment_name, region):\n",
    "    for _, row in region.iterrows():\n",
    "        if row['region'].lower() in touranment_name.lower():\n",
    "            return row['reg_id']\n",
    "    return \"reg_4\"\n",
    "\n",
    "def create_draft_table(df):\n",
    "    filas_transformadas = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        picks = [\n",
    "            row['team_1_select_1'], row['team_2_select_1'],\n",
    "            row['team_1_select_2'], row['team_2_select_2'],\n",
    "            row['team_1_select_3'], row['team_2_select_3'],\n",
    "            row['decider']\n",
    "        ]\n",
    "\n",
    "        for pick_num, map_name in enumerate(picks, start=1):\n",
    "            filas_transformadas.append({\n",
    "                'team': row['team'],\n",
    "                'series_id': row['series_id'],\n",
    "                'order': row['order'],\n",
    "                'bo': row['bo'],\n",
    "                'pick': pick_num,\n",
    "                'map_name': map_name,\n",
    "                \"match_instance\" : row[\"match_instance\"]\n",
    "            })\n",
    "\n",
    "    new_df = pd.DataFrame(filas_transformadas)\n",
    "    return new_df\n",
    "\n",
    "def first_ban(row):\n",
    "    if (row['match_instance'] != \"gf\"):\n",
    "        if (row['pick'] == 1):        \n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif (row['match_instance'] == \"gf\"):\n",
    "        if (row['pick'] == 1 or row['pick'] == 2):        \n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    else:\n",
    "         return 0\n",
    "\n",
    "def second_ban(row):\n",
    "    \n",
    "        if row['pick'] == 5 and row['bo'] == 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "def first_pick(row):\n",
    "\n",
    "        if row['pick'] == 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "   \n",
    "def second_pick(row):\n",
    "        if row['pick'] == 5 and row['bo'] == 5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def decider_pick(row):\n",
    "    if row['pick'] == 7:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37a3d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should round only once \n",
    "region_name = [\"americas\",\"emea\",\"china\",\"pacific\",\"global\"]\n",
    "\n",
    "df_region = pd.DataFrame(data=region_name, columns=[\"region\"])\n",
    "text_to_index(df_region,\"reg\",number=0,extra_id=\"\")\n",
    "\n",
    "#This should run each time a new tournament is add\n",
    "\n",
    "tournaments = tournament_names('csv')\n",
    "df_tournaments = pd.DataFrame(data=tournaments,columns=[\"tournament_name\"])\n",
    "tournament_name_list = ['Valorant Masters Toronto 2025', 'VCT 2025: Americas Stage 1',\n",
    "       'VCT 2025: China Stage 1', 'VCT 2025: EMEA Stage 1',\n",
    "       'VCT 2025: Pacific Stage 1']\n",
    "df_tournaments[\"tournament_vlr_name\"] = pd.Series(tournament_name_list)\n",
    "\n",
    "df_tournaments['reg_id'] = df_tournaments['tournament_name'].apply(lambda x: region_by_id(x, df_region))\n",
    "\n",
    "text_to_index(df_tournaments,\"tour\")\n",
    "\n",
    "df_region.to_csv(path_or_buf='tables/table_region.csv',index=False,encoding='iso-8859-1')\n",
    "df_tournaments.to_csv(path_or_buf='tables/table_tournament.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90c80449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tournament_name</th>\n",
       "      <th>tournament_vlr_name</th>\n",
       "      <th>reg_id</th>\n",
       "      <th>tour_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valorant_masters_toronto_2025</td>\n",
       "      <td>Valorant Masters Toronto 2025</td>\n",
       "      <td>reg_4</td>\n",
       "      <td>tour_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vct_2025_americas_stage_1</td>\n",
       "      <td>VCT 2025: Americas Stage 1</td>\n",
       "      <td>reg_0</td>\n",
       "      <td>tour_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vct_2025_china_stage_1</td>\n",
       "      <td>VCT 2025: China Stage 1</td>\n",
       "      <td>reg_2</td>\n",
       "      <td>tour_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vct_2025_emea_stage_1</td>\n",
       "      <td>VCT 2025: EMEA Stage 1</td>\n",
       "      <td>reg_1</td>\n",
       "      <td>tour_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vct_2025_pacific_stage_1</td>\n",
       "      <td>VCT 2025: Pacific Stage 1</td>\n",
       "      <td>reg_3</td>\n",
       "      <td>tour_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tournament_name            tournament_vlr_name reg_id tour_id\n",
       "0  valorant_masters_toronto_2025  Valorant Masters Toronto 2025  reg_4  tour_0\n",
       "1      vct_2025_americas_stage_1     VCT 2025: Americas Stage 1  reg_0  tour_1\n",
       "2         vct_2025_china_stage_1        VCT 2025: China Stage 1  reg_2  tour_2\n",
       "3          vct_2025_emea_stage_1         VCT 2025: EMEA Stage 1  reg_1  tour_3\n",
       "4       vct_2025_pacific_stage_1      VCT 2025: Pacific Stage 1  reg_3  tour_4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tournaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "589a88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_draft_concat = concat_csv_from_different_folders(folder=\"csv\", prefix=\"draft_\")\n",
    "df_team = pd.DataFrame(df_draft_concat[\"team\"].unique(), columns=[\"team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9cf40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teams by region:\n",
    "df_teams_china = pd.read_csv(\"csv/vct_2025_china_stage_1/draft_vct_2025_china_stage_1.csv\",encoding='iso-8859-1')\n",
    "df_teams_americas = pd.read_csv(\"csv/vct_2025_americas_stage_1/draft_vct_2025_americas_stage_1.csv\",encoding='iso-8859-1')\n",
    "df_teams_emea = pd.read_csv(\"csv/vct_2025_emea_stage_1/draft_vct_2025_emea_stage_1.csv\",encoding='iso-8859-1')\n",
    "df_teams_pacific = pd.read_csv(\"csv/vct_2025_pacific_stage_1/draft_vct_2025_pacific_stage_1.csv\",encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce07fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should run one by year\n",
    "df_teams_amer_for_merge = pd.DataFrame(df_teams_americas[\"team\"].unique(),columns=[\"team\"])\n",
    "df_teams_amer_for_merge[\"region\"] = \"reg_0\"\n",
    "\n",
    "df_teams_emea_for_merge = pd.DataFrame(df_teams_emea[\"team\"].unique(),columns=[\"team\"])\n",
    "df_teams_emea_for_merge[\"region\"] = \"reg_1\"\n",
    "\n",
    "df_teams_china_for_merge = pd.DataFrame(df_teams_china[\"team\"].unique(),columns=[\"team\"])\n",
    "df_teams_china_for_merge[\"region\"] = \"reg_2\"\n",
    "\n",
    "df_teams_apac_for_merge = pd.DataFrame(df_teams_pacific[\"team\"].unique(),columns=[\"team\"])\n",
    "df_teams_apac_for_merge[\"region\"] = \"reg_3\"\n",
    "\n",
    "df_teams_concat = pd.concat(\n",
    "    [\n",
    "        df_teams_amer_for_merge,\n",
    "        df_teams_emea_for_merge,\n",
    "        df_teams_china_for_merge,\n",
    "        df_teams_apac_for_merge,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "text_to_index(df_teams_concat,\"team\")\n",
    "#save \n",
    "df_teams_concat.to_csv(path_or_buf='tables/table_teams.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83c09e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update when a new player is add\n",
    "df_players_stats = concat_csv_from_different_folders(folder=\"csv\", prefix=\"player_stats\")\n",
    "df_players = df_players_stats[['player','team']].drop_duplicates(subset=['player'],ignore_index=True)\n",
    "text_to_index(df_players,\"player\")\n",
    "\n",
    "df_players_id = pd.merge(df_players, df_teams_concat[[\"team\",\"team_id\"]],how=\"left\", left_on=\"team\", right_on=\"team\")\n",
    "\n",
    "df_players_id = pd.merge(df_players_id, df_teams_concat[[\"team_id\",\"region\"]],how=\"left\", left_on=\"team_id\", right_on=\"team_id\")\n",
    "\n",
    "df_players_id.to_csv(path_or_buf='tables/table_players.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36cfd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Player performance\n",
    "\n",
    "df_round_detail = concat_csv_from_different_folders(folder=\"csv\", prefix=\"round_detail\")\n",
    "\n",
    "df_filter_map = df_round_detail[\"map\"] != \"all\"\n",
    "df_round_detail_filter = df_round_detail[df_filter_map]\n",
    "df_round_detail_filter[\"date-map\"] = df_round_detail_filter[\"date\"] + \"-\" + df_round_detail_filter[\"map\"]\n",
    "\n",
    "df_maps_id = pd.DataFrame(df_round_detail_filter[\"date-map\"].unique(), columns=[\"date-map\"])\n",
    "text_to_index(df_maps_id,\"map\")\n",
    "\n",
    "df_maps_id[['date', 'map']] = df_maps_id[\"date-map\"].str.rsplit('-', n=1, expand=True)\n",
    "\n",
    "df_match_ids = pd.DataFrame(data= df_maps_id[\"date\"].unique(), columns=[\"date\"])\n",
    "text_to_index(df_match_ids,\"series\")\n",
    "\n",
    "df_maps_id = pd.merge(df_maps_id, df_match_ids[[\"date\",\"series_id\"]],how=\"left\", left_on=\"date\", right_on=\"date\")\n",
    "\n",
    "df_maps_id.to_csv(path_or_buf='tables/table_maps_id.csv',index=False,encoding='iso-8859-1')\n",
    "\n",
    "df_match_ids.to_csv(path_or_buf='tables/table_match_id.csv',index=False,encoding='iso-8859-1')\n",
    "\n",
    "df_round_detail_filter = pd.merge(df_round_detail_filter, df_maps_id[[\"date-map\",\"map_id\",\"series_id\"]],how=\"left\", left_on=\"date-map\", right_on=\"date-map\")\n",
    "\n",
    "df_round_detail_filter.to_csv(path_or_buf='tables/table_player_performance.csv',index=False,encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc861da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Team economy\n",
    "\n",
    "df_team_economy = concat_csv_from_different_folders(folder=\"csv\", prefix=\"team_economy\")\n",
    "\n",
    "columns_update = [\"team_a_economy\",\"team_b_economy\",\"team_a_bank\",\"team_b_bank\"]\n",
    "\n",
    "for column_name in columns_update:\n",
    "    df_team_economy[column_name] = df_team_economy[column_name].apply(convert_k)\n",
    "\n",
    "df_team_economy[\"date-map\"] = df_team_economy[\"date\"] + \"-\" + df_team_economy[\"map\"]\n",
    "\n",
    "df_team_economy = pd.merge(df_team_economy, df_maps_id[[\"date-map\",\"map_id\",\"series_id\"]],how=\"left\", left_on=\"date-map\", right_on=\"date-map\")\n",
    "\n",
    "df_team_economy.to_csv(path_or_buf='tables/table_team_economy.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2d588b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#player stats\n",
    "\n",
    "df_player_stats = concat_csv_from_different_folders(folder=\"csv\", prefix=\"player_stats\")\n",
    "\n",
    "df_filter_map = df_player_stats[\"map\"] != \"all\"\n",
    "df_player_stats = df_player_stats[df_filter_map]\n",
    "\n",
    "df_player_stats[\"date-map\"] = df_player_stats[\"date\"] + \"-\" + df_player_stats[\"map\"]\n",
    "\n",
    "df_player_stats = pd.merge(df_player_stats, df_maps_id[[\"date-map\",\"map_id\",\"series_id\"]],how=\"left\", left_on=\"date-map\", right_on=\"date-map\")\n",
    "\n",
    "df_player_stats.to_csv(path_or_buf='tables/table_player_stats.csv',index=False,encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb5ab8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draft Not so sure about this one esta todo raro, para tener un formato que funciona en powerbi \n",
    "\n",
    "df_draft_concat = concat_csv_from_different_folders(folder=\"csv\", prefix=\"draft_\")\n",
    "df_draft_concat[\"match_instance\"] = df_draft_concat[\"source_url\"].apply(get_game_instance)\n",
    "\n",
    "df_draft_concat = pd.merge(df_draft_concat, df_maps_id[[\"date\",\"series_id\"]],how=\"left\", left_on=\"date\", right_on=\"date\")\n",
    "\n",
    "df_draft_concat_fix = create_draft_table(df_draft_concat)\n",
    "\n",
    "df_draft_concat_fix.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df_draft_concat_fix['1st_ban'] = df_draft_concat_fix.apply(first_ban,axis=1)\n",
    "\n",
    "df_draft_concat_fix['2nd_ban'] = df_draft_concat_fix.apply(second_ban,axis=1)\n",
    "\n",
    "df_draft_concat_fix['1st_pick'] = df_draft_concat_fix.apply(first_pick, axis=1)\n",
    "\n",
    "df_draft_concat_fix['2nd_pick'] = df_draft_concat_fix.apply(second_pick,axis=1)\n",
    "\n",
    "df_draft_concat_fix['decider'] = df_draft_concat_fix.apply(decider_pick,axis=1)\n",
    "\n",
    "df_draft_concat_fix.to_csv(path_or_buf='tables/table_draft.csv',index=False,encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b715ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round stats\n",
    "\n",
    "df_round_concat = concat_csv_from_different_folders(folder=\"csv\", prefix=\"round_detail\")\n",
    "\n",
    "#table with the maps\n",
    "df_maps_name_id = pd.DataFrame(df_round_concat[\"map\"].unique(), columns=[\"map\"])\n",
    "text_to_index(df_maps_name_id,\"map\")\n",
    "\n",
    "df_maps_name_id.to_csv(path_or_buf='tables/table_maps_name_id.csv',index=False,encoding='iso-8859-1')\n",
    "\n",
    "#continue with round stats\n",
    "\n",
    "df_round_concat[\"date-map\"] = df_round_concat[\"date\"] + \"-\" + df_round_concat[\"map\"]\n",
    "\n",
    "df_round_concat = pd.merge(df_round_concat, df_maps_id[[\"date-map\",\"map_id\",\"series_id\"]],how=\"left\", left_on=\"date-map\", right_on=\"date-map\")\n",
    "\n",
    "df_round_concat.to_csv(path_or_buf='tables/table_round_info.csv',index=False,encoding='iso-8859-1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
